"""Module containing both class and CLI for analyzing FEP calculations setup through the program setupFEP"""

import argparse
import json
import os
import re
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from cinnabar import stats as cstats
from matplotlib.lines import Line2D
from matplotlib.patches import Patch

from .IO import read_qfep, run_command
from .logger import logger, setup_logger
from .settings.settings import Q_PATHS


def info_from_run_file(file_path: Path):
    """Extract the FEP temperature from a run file."""
    info = {"temperature": None, "replicates": None}
    run_files = sorted(list(file_path.glob("run*.sh")))
    if len(run_files) == 0:
        logger.error(f"No run files found in {file_path}")
    elif len(run_files) > 1:
        logger.warning(f"Multiple run files found in {file_path}!! Using the first one.")
    run_file = run_files[0]
    temp_pattern = re.compile(r"temperatures=\((\d+)\)")
    seeds_pattern = re.compile(r"seeds=\(([0-9\s]+)\)")
    with run_file.open("r", encoding="utf-8") as _file:
        for line in _file:
            temp_match = temp_pattern.search(line)
            seeds_match = seeds_pattern.match(line)
            if temp_match:
                info["temperature"] = temp_match.group(1)
            if seeds_match:
                info["random_seeds"] = seeds_pattern.findall(line)[0].split()
                info["replicates"] = len(info["random_seeds"])

    if any([v is None for v in info.values()]):
        logger.error(f"Could not extract temperature and/or replicates from {run_file}")
    return info


class FepReader:
    """Class to analyze FEP output files. This wrapper class will read, structure the files
    and enable input/output operation with the analyzed data.
    """

    def __init__(self, system: str, target_name: str, mapping_json: str) -> None:
        """Initialize the FEP reader class. This class will store the FEP information inside
        `self.data` and will be used to analyze the results & generate plots.

        Args:
            system: which system to be loaded first. This should be a directory containing
                the FEP directories, named by default with the format `FEP_*`.
            target_name: name of the target protein so we can load the correct FEP directories.
        """
        self._load_mapping_json(mapping_json)
        self.exp_key = None  # will be defined from running load_experimental_data
        self.feps = []
        self.methods_list = ["dG", "dGf", "dGr", "dGos", "dGbar"]
        self.cwd = Path.cwd()
        self.data = {}
        self.system = None
        self.target_name = target_name
        self.load_system(system)
        self.read_fep_inputs()

    def _load_mapping_json(self, json_file: str) -> dict:
        with open(json_file) as json_file:
            self.mapping_json = json.load(json_file)  # e.g.: generated by qlomap

    def _check_method_in_result(self, method):
        if "result" not in self.data:
            logger.error("No results to plot. Run calculate_ddG first.")
            raise ValueError()
        elif method not in self.data["result"]:
            logger.error(
                f"{method} not in result dictionary. Pick one of the following: "
                f"{', '.join(self.data['result'].keys())}"
            )
            raise ValueError()

    @staticmethod
    def init_from_json(data_json: str, target_name: str, mapping_json: str):
        """initialize object from two json files; one with the FEP data and the other with the
        mapping of the perturbations. This method will return a FepReader object with the data
        already loaded.

        Args:
            data_json: json file ouptut from `FepReader.save_json_data`.
            target_name: the name of the target that is being loaded.
            mapping_json: the path to the json file with the mapping; e.g.: generated by qlomap.

        Returns:
            FepReader object with the data already loaded.
        """
        data_dict = json.loads(data_json)
        system = [k for k in data_dict if k != "result"][0]
        feps = [k for k in data_dict[system]]
        fep_reader = FepReader(system=system, target_name=target_name, mapping_json=mapping_json)
        fep_reader.data = data_dict
        fep_reader.feps = feps
        return fep_reader

    def load_system(self, system: str):
        """This method will load the FEP directories within a system directory. The reason
        for this is the way setupFEP is structured. When running it, it will create two
        different diretories for storing the perturbation; `1.water` and `2.protein`."""
        fep_dirs = sorted(list((self.cwd / system).glob("FEP_*")))
        self.data.update({system: {}})
        self.data[system].update({_dir.name: {"root": str(_dir.absolute())} for _dir in fep_dirs})
        self.system = system

    def load_new_system(self, system: str):
        """This method will load a new system into the data dictionary."""
        self.load_system(system)
        self.read_fep_inputs()

    def read_fep_inputs(self):
        """Load basic FEP information from the input files, including temperature,
        number of replicates, and lambda sum. Information is stored in`self.data`."""
        for fep in self.data[self.system]:
            _dir = Path(self.data[self.system][fep]["root"])
            run_info = info_from_run_file(_dir / "inputfiles")
            temperature = run_info["temperature"]
            replicates = run_info["replicates"]
            inputs = sorted(list(_dir.glob("inputfiles/md*.inp")))
            fep_files = sorted(list(_dir.glob("inputfiles/FEP*.fep")))
            fep_stages = []
            for fep_file in fep_files:
                fep_stages.append(fep_file.stem)
            if len(fep_stages) > 1:  # Are there cases where we'll have more than 1?
                logger.warning(f"Multiple FEP files found in {fep}: {fep_files}!! Using the first...")
            fep_stage = fep_stages[0]
            lambda_sum = len(fep_files) * (len(inputs) - 1)

            # register the ligand names in the dictionary for further results analysis
            ligands = fep.lstrip("FEP_")
            if len(ligands.split("_")) == 2:
                _from, _to = ligands.split("_")
            else:
                for edge in self.mapping_json["edges"]:
                    if "_".join([edge["from"], edge["to"]]) == ligands:
                        _from, _to = edge["from"], edge["to"]
                        break
            try:
                self.data[self.system][fep].update(
                    {  # populate the dictionary with the FEP information
                        "lambda_sum": lambda_sum,
                        "fep_stage": fep_stage,
                        "temperature": str(temperature),
                        "replicates": replicates,
                        "from": _from,
                        "to": _to,
                    }
                )
            except UnboundLocalError as e:
                logger.error(
                    f"Failed to find the ligands for {fep}. Are you sure all calculations ran? Error: \n{e}"
                )

    def run_qfep(self, qfep_file: Path):
        """Run qfep for the given FEP directory."""
        qfep = Q_PATHS["QFEP"]
        os.chdir(str(qfep_file.parent.absolute()))
        options = " < qfep.inp > qfep.out"
        run_command(qfep, options, string=True)
        os.chdir(str(self.cwd.absolute()))

    def read_single_replicate(self, qfep_repli_path: Path):
        """Reads a single replicate qfep.out file and returns the energies and a list.
        If the list is not empty, it means that the replicate failed to be read.

        Args:
            qfep_repli_path: path to the qfep.out file. e.g.: `<root>/FEP_lig1_lig2/FEP1/298/2/qfep.out`

        Returns:
            energies: a list with the energies for the replicate.
            failed_replicate: a list with the replicates that failed to be read.
        """
        failed_replicate = []
        if qfep_repli_path.stat().st_size == 0:  # if the file is empty, try runnign qfep again
            logger.warning(f"Empty qfep.out file: {qfep_repli_path}. Trying to run qfep again...")
            self.run_qfep(qfep_repli_path)
        logger.debug(f"    Reading qfep.out file: {qfep_repli_path}")
        repID = int(qfep_repli_path.parent.name)
        try:
            # TODO: shall we also support the verbose output? -> see IO.read_qfep_verbose
            energies = read_qfep(qfep_repli_path)
        except OSError as e:  # if the file is empty
            logger.error(f"Failed to read energies from {qfep_repli_path}. Error: \n{e}")
            failed_replicate.append(repID)
            energies = np.array([np.nan] * len(self.methods_list))  # Assuming 5 energy methods
        except IndexError as e:
            logger.error(f"Failed to read energies from {qfep_repli_path}. Error: \n{e}")
            failed_replicate.append(repID)
            energies = np.array([np.nan] * len(self.methods_list))
        # if the qfep.out is not in the correct format due to not being fully ran, the loop won't
        # retrieve the energies, causing an UnboundLocalError.
        except UnboundLocalError as e:
            logger.error(f"Failed to read energies from {qfep_repli_path}. Error: \n{e}")
            failed_replicate.append(repID)
            energies = np.array([np.nan] * len(self.methods_list))  # Assuming 5 energy methods
        return energies, failed_replicate

    def read_perturbations(self):
        """Read the ran perturbations. Running this method will populate the `self.data` dictionary
        with the FEPs and their respective delta-G's for the loaded system (self.system)."""
        feps = [k for k in self.data[self.system]]

        for fep in feps:
            logger.info(f"Reading FEP: {fep}")
            fep_dict = self.data[self.system][fep]
            n_replicates = int(fep_dict["replicates"])
            _dir = Path(fep_dict["root"])
            replicate_root = _dir / fep_dict["fep_stage"] / fep_dict["temperature"]
            replicate_qfep_files = sorted(  # here we use the int to sort the replicates
                list(replicate_root.glob("*/qfep.out")), key=lambda x: int(x.parent.name)
            )

            # deal with missing qfep.out files
            if len(replicate_qfep_files) < n_replicates:
                logger.warning(
                    "Not all replicates have qfep.out files in the directory. Creating empty files..."
                )
                for i in range(1, n_replicates + 1):
                    if not (replicate_root / str(i) / "qfep.out").exists():
                        (replicate_root / str(i) / "qfep.out").touch()
                replicate_qfep_files = sorted(
                    list(replicate_root.glob("*/qfep.out")), key=lambda x: int(x.parent.name)
                )
                logger.info(f"Created {n_replicates} empty qfep.out files in {replicate_root}")
                logger.debug("Files created:\n" + "\n".join([str(f) for f in replicate_qfep_files]))

            energies = {}
            method_results = {method: {} for method in self.methods_list}
            failed_replicates = []
            all_replicates = [i for i in range(1, int(fep_dict["replicates"]) + 1)]
            for rep in replicate_qfep_files:
                repID = int(rep.parent.name)
                replicate_energies, failed = self.read_single_replicate(rep)
                energies[repID] = replicate_energies
                failed_replicates.extend(failed)
            all_energies_arr = []
            # per different type of energy, populate the methods dictionary
            for mname in self.methods_list:
                method_idx = self.methods_list.index(mname)
                method_energies = np.array([energies[repID][method_idx] for repID in all_replicates])
                all_energies_arr.append(", ".join([f"{n:.3f}" for n in method_energies]))
                method_results[mname] = {
                    "energies": method_energies.tolist(),
                    "avg": np.nanmean(method_energies),
                    "sem": float(np.nanstd(method_energies) / np.sqrt(method_energies.shape)),
                    "std": np.nanstd(method_energies),
                }
            logger.debug("energies:\n" + "\n".join(all_energies_arr))

            self.data[self.system][fep].update({"CrashedReplicates": failed_replicates})
            self.data[self.system][fep].update({"FEP_result": method_results})

    def create_result_key(self):
        if "result" not in self.data:
            self.data.update({"result": {}})
        for method in self.methods_list:
            new_key = f"d{method}"
            self.data["result"].update({new_key: {}})

    def calculate_ddG(self, water_sys: str = "1.water", protein_sys: str = "2.protein"):
        """After running `read_perturbations`, for both the water and the protein systems,
        running this method will calculate the ddG for each FEP and store it in `self.data`
        under the key `result`.

        Running this method will also populate the `self.feps` list with the FEPs that were
        analyzed and checked for matching variables.

        Args:
            water_sys: name of the water system that was read. Defaults to '1.water'.
            protein_sys: name of the protein system that was read. Defaults to '2.protein'.
        """
        self.create_result_key()
        systems = [water_sys, protein_sys]
        # assert both systems have the same FEPs
        prot_feps = sorted([k for k in self.data[protein_sys]])
        water_feps = sorted([k for k in self.data[water_sys]])
        assert prot_feps == water_feps, "FEPs do not match between protein and water!!"
        for fep in water_feps:
            w_fep = self.data[water_sys][fep]
            p_fep = self.data[protein_sys][fep]
            w_result = w_fep["FEP_result"]
            p_result = p_fep["FEP_result"]

            for _sys in systems:
                # check for inconsistencies
                if w_fep["fep_stage"] != p_fep["fep_stage"]:
                    logger.error(f"FEP stages do not match between water/{fep} and protein/{fep}.")
                    continue
                if w_fep["temperature"] != p_fep["temperature"]:
                    logger.error(f"Temperatures do not match between water/{fep} and protein/{fep}.")
                    continue
                if w_fep["lambda_sum"] != p_fep["lambda_sum"]:
                    logger.error(f"Lambda sums do not match between water/{fep} and protein/{fep}.")
                    continue

            for method in w_result:
                delta_method = f"d{method}"
                ddG = p_result[method]["avg"] - w_result[method]["avg"]
                ddG_sem = float(np.sqrt(p_result[method]["sem"] ** 2 + w_result[method]["sem"] ** 2))
                ddG_std = float(np.sqrt(p_result[method]["std"] ** 2 + w_result[method]["std"] ** 2))
                self.data["result"][delta_method].update(
                    {
                        fep: {
                            f"{delta_method}_avg": ddG,
                            f"{delta_method}_sem": ddG_sem,
                            f"{delta_method}_std": ddG_std,
                            "from": w_fep["from"],
                            "to": w_fep["to"],
                        }
                    }
                )
            self.feps.append(fep)

    def load_experimental_data(self, exp_key: str):
        """Load the experimental data found in the input json file and populate the existing
        result `self.data['result']` dictionary with the experimental values

        Args:
            exp_key: the key in the `self.mapping_json` file that contains the experimental data.
        """
        self.exp_key = exp_key
        if "result" not in self.data:
            logger.error("No results to plot. Run calculate_ddG first.")
            return
        for fep in self.feps:
            _from = self.data[self.system][fep]["from"]
            _to = self.data[self.system][fep]["to"]

            # search ligands in the edges
            for edge in self.mapping_json["edges"]:
                if edge["from"] == _from and edge["to"] == _to:
                    ddG = edge[exp_key]
                    break

            # populate the result dictionary
            if ddG is not None:
                if "experimental" not in self.data["result"]:
                    self.data["result"].update({"experimental": {}})
                self.data["result"]["experimental"].update({fep: {"from": _from, "to": _to, "value": ddG}})
            else:
                print(f"Error: ddG not found for {fep}")

    def populate_mapping_dictionary(self, method, output_file: str | Path | None = None):
        """Calling this method will populate the mapping dictionary with the calculated
        ddG values for the given method. The output will be a json file with the updated
        mapping dictionary.

        Args:
            method: method used to calculate the ddG. Must be one of the keys in the result dictionary.
            output_file: if not None, will save it to the designated path. Defaults to None.
        """
        self._check_method_in_result(method)

        for edge in self.mapping_json["edges"]:
            _from = edge["from"]
            _to = edge["to"]
            for fep in self.feps:
                fep_dict = self.data["result"][method][fep]
                if fep_dict["from"] == _from and fep_dict["to"] == _to:
                    edge.update(
                        {
                            "Q_ddG_avg": fep_dict[f"{method}_avg"],
                            "Q_ddG_sem": fep_dict[f"{method}_sem"],
                            "Q_ddG_std": fep_dict[f"{method}_std"],
                        }
                    )
        if output_file is not None:
            if isinstance(output_file, str):
                output_file = Path(output_file)
            with output_file.open("w") as f:
                json.dump(self.mapping_json, f, indent=4)

    @staticmethod
    def prepare_df(json_dict, experimental_data: bool = True):
        pref = "dg" if "dg_error" in json_dict["edges"][0] else "ddg"
        df = pd.DataFrame(json_dict["edges"])
        if experimental_data:
            df = (
                df.assign(
                    ddg_value=lambda x: x[pref + "_value"],
                    residual=lambda x: x[pref + "_value"] - x["Q_ddG_avg"],
                    residual_abs=lambda x: x["residual"].abs(),
                )
                .sort_values("residual_abs", ascending=False)
                .drop(columns="residual_abs")
            )
        df = df.assign(
            fep_name=lambda x: "FEP_" + x["from"] + "_" + x["to"],
        )
        return df

    @staticmethod
    def create_ddG_plot(
        results_df: pd.DataFrame,
        margin: float = 1.0,
        xylims: tuple | None = None,
        output_path: str | None = None,
        target_name: str | None = None,
        savefig: bool = False,
    ):
        """Creates the ddG plot for the FEP that has already been analyzed. The plot will
        show the experimental (X axis) vs mean predicted values (Y axis), with error bars
        representing the standard error of the mean (SEM).

        Args:
            reuslts_df: pd.DataFrame with the results from the FEP, output from `prepare_df`.
            margin: margin value to be added/subtracted to the max/min values obtained. Defaults to 1.0.
            xylims: if values are passed, x&y min will be xylims[0] and max will be [1]. Defaults to None.
            output_path: path to save the plot. If None, the plot will not be saved. Defaults to None.
            target_name: name of the target protein to be added in the plot. Defaults to None.
            savefig: if True, will save the plot to the output_path. Defaults to False.

        Returns:
            the matplotlib figure and axis objects (fig, ax).
        """
        fep_names = results_df["fep_name"].values
        avg_values = results_df["Q_ddG_avg"].values
        sem_values = results_df["Q_ddG_sem"].values
        exp_values = results_df["ddg_value"].values
        nan_val_idxs = np.where(np.isnan(avg_values))[0]
        if len(nan_val_idxs) > 0:
            logger.warning(f"Dropping FEPs with nan values: {fep_names[nan_val_idxs]}")
            mask = ~np.isin(np.arange(len(avg_values)), nan_val_idxs)
            avg_values = avg_values[mask]
            sem_values = sem_values[mask]
            exp_values = exp_values[mask]

        ## CALCULATE STATISTICS
        def result_to_latex(res, latexify_each=False):  # TODO: move this out of this method?
            """Round cinnabar's output to one decimal case and return a LaTeX string."""
            mle = round(res["mle"], 2)
            low = round(res["low"], 2)
            high = round(res["high"], 2)

            if latexify_each:
                return f"${mle:.2f}_{{{low}}}^{{{high}}}$"
            else:
                return f"{mle:.2f}_{{{low}}}^{{{high}}}"

        statistics = ["RMSE", "MUE", "KTAU"]
        stats_dict = {}
        for stat in statistics:
            cinnabar_stats = cstats.bootstrap_statistic(avg_values, exp_values, statistic=stat)
            stats_dict[stat] = result_to_latex(cinnabar_stats)

        if xylims is not None:
            assert len(xylims) == 2, "xylims must be a tuple with 2 elements."
            assert xylims[0] < xylims[1], "xylims[0] must be smaller than xylims[1]."
            min_val = xylims[0]
            max_val = xylims[1]
        else:
            all_values = avg_values + exp_values
            min_val = min(all_values) - margin
            max_val = max(all_values) + margin

        fig, ax = plt.subplots()

        plt.errorbar(
            exp_values,
            avg_values,
            yerr=sem_values,
            fmt="o",
            color="black",
            ecolor="black",
            elinewidth=2.0,
            capsize=0,
            zorder=4,
        )
        plt.plot([min_val, max_val], [min_val, max_val], "k-", linewidth=1.5, zorder=3)  # Black identity line

        # Highlight predictions within 1 and 2 kcal/mol of the experimental affinity
        ax.fill_between(
            [min_val, max_val],
            [min_val - 1, max_val - 1],
            [min_val + 1, max_val + 1],
            color="darkgray",
            alpha=0.5,
            zorder=2,
        )
        ax.fill_between(
            [min_val, max_val],
            [min_val - 2, max_val - 2],
            [min_val + 2, max_val + 2],
            color="lightgray",
            alpha=0.5,
            zorder=1,
        )

        # set labels, make it square and add legend
        plt.title(
            f"{(target_name + ' - ' if target_name is not None else '')}"
            rf"$\Delta\Delta Gbar$ plot ($N={len(exp_values)}$)"
        )
        plt.xlabel("$\Delta\Delta G_{exp} [kcal/mol]$")  # noqa: W605
        plt.ylabel("$\Delta\Delta G_{pred} [kcal/mol]$")  # noqa: W605
        plt.xlim(min_val, max_val)
        plt.ylim(min_val, max_val)
        ax.set_aspect("equal", adjustable="box")

        # add statistics to the plot
        unit = r"\frac{kcal}{mol}"
        text_body = (
            f"$\\tau = {stats_dict['KTAU']}$ (Kendall's $\\tau$)",
            f"RMSE = ${stats_dict['RMSE']}  {unit}$",
            f"MUE = ${stats_dict['MUE']}  {unit}$",
        )
        logger.info(f"Stats: {' '.join(text_body)}")
        hori_height = 0.35
        spacing = 0.085
        txt_positions = (
            (1.04, hori_height),
            (1.04, hori_height - spacing),
            (1.04, hori_height - spacing * 2),
        )
        for txt_position, body in zip(txt_positions, text_body):
            plt.text(
                *txt_position,
                body,
                fontsize=12,
                verticalalignment="bottom",
                horizontalalignment="left",
                transform=ax.transAxes,
            )

        legend_elements = [
            Line2D([0], [0], color="k", linestyle="-", label="Identity line"),
            Patch(facecolor="darkgray", alpha=0.5, label="Within 1 kcal/mol"),
            Patch(facecolor="lightgray", alpha=0.5, label="Within 2 kcal/mol"),
        ]

        ax.legend(
            handles=legend_elements,
            bbox_to_anchor=(1.04, 0),
            loc="lower left",
            borderaxespad=0,
            frameon=False,
        )
        if savefig:
            if output_path is None:
                output_path = Path().cwd()
                logger.info("Using default name to save the plot at the current working directory...")
                fig.savefig(f"{target_name}_ddG_plot.png", dpi=300, bbox_inches="tight")
                return fig, ax
            if isinstance(output_path, str):
                output_path = Path(output_path)
            assert isinstance(output_path, Path), "output_path must be a string or a Path object."
            if output_path.isdir():
                output_path = output_path / f"{target_name}_ddG_plot.png"
                logger.info(f"Using default name to save the plot at {output_path}")
            elif output_path.exits():
                logger.warning(f"File {output_path} already exists. Overwriting...")
            fig.savefig(output_path, dpi=300, bbox_inches="tight")
        return fig, ax

    def save_json_data(self, out_path: str | Path | None = None):
        """Save the data dictionary to a json file.

        Args:
            out_path: path to save the json file.
        """
        if out_path is None:
            out_path = f"{self.target_name}_FEP_results.json"
        if isinstance(out_path, str):
            out_path = Path(out_path)
        with out_path.open("w") as f:
            json.dump(self.data, f, indent=4)


def parse_arguments() -> argparse.Namespace:
    """Method to parse the arguments."""
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description="Analyze FEP output files and generate plots.",
    )
    parser.add_argument(
        "-p",
        "--protein-dir",
        dest="protein_dir",
        required=False,
        default="2.protein",
        help=(
            "Path to the directory containing the protein system FEPs. "
            "Will default to `2.protein` in the current working directory."
        ),
    )

    parser.add_argument(
        "-w",
        "--water-dir",
        dest="water_dir",
        required=False,
        default="1.water",
        help=(
            "Path to the directory containing the water system FEPs. "
            "Will default to `1.water` in the current working directory."
        ),
    )

    # parser.add_argument(
    #     "-ignore",
    #     "--ignore_missing",
    #     dest="ignore_missing",
    #     action="store_true",
    #     help=(
    #         "Ignore missing qfep.out files and continue with the data extraction if missing files are encountered."
    #     ),
    # )

    parser.add_argument(
        "-j",
        "--json-file",
        dest="json_file",
        required=True,
        help=(
            "Path to the .json file containing the mapping of the perturbations. "
            "This should be the same file used to run the setupFEP script."
        ),
    )

    parser.add_argument(
        "-exp",
        "--experimental-key",
        dest="experimental_key",
        help=("Key in the provided .json file that contains the experimental data."),
        type=str,
        required=False,
        default=None,
    )

    parser.add_argument(
        "-experr",
        "--experimental-error-key",
        dest="exp_error",
        help=("Key in the provided .json file that contains the error for the experimental data."),
        type=str,
        required=False,
        default=None,
    )

    parser.add_argument(
        "-t",
        "--target",
        dest="target",
        required=True,
        help="Name of the protein target; used to save the plot.",
    )

    parser.add_argument(
        "-m",
        "--method",
        required=False,
        default="ddGbar",
        choices=["ddG", "ddGf", "ddGr", "ddGos", "ddGbar"],
        help="Energy method to be used for the plot. Defaults to ddGbar.",
    )

    parser.add_argument(
        "-log",
        "--log-level",
        dest="log",
        required=False,
        default="info",
        help="Set the log level for the logger. Defaults to `info`.",
        choices=["trace", "debug", "info", "warning", "error", "critical"],
    )

    return parser.parse_args()


def main(args):
    setup_logger(level=args.log)
    fep_reader = FepReader(system=args.water_dir, target_name=args.target, mapping_json=args.json_file)
    fep_reader.read_perturbations()
    fep_reader.load_new_system(system=args.protein_dir)
    fep_reader.read_perturbations()
    fep_reader.calculate_ddG()
    fep_reader.save_json_data()

    results_file = args.json_file.replace(".json", "_ddG.json")
    fep_reader.populate_mapping_dictionary(method=args.method, output_file=results_file)
    if args.experimental_key is not None:
        fep_reader.load_experimental_data(exp_key=args.experimental_key)
        results_json = json.loads((Path.cwd() / results_file).read_text())
        results_df = fep_reader.prepare_df(results_json)
        fig, ax = fep_reader.create_ddG_plot(results_df=results_df)
    else:
        results_json = json.loads((Path.cwd() / results_file).read_text())
        results_df = fep_reader.prepare_df(results_json, experimental_data=False)


def main_exe():
    args = parse_arguments()
    main(args)


# def write_re2pdb(self): # TODO: port this to the new class
#     curdir = os.getcwd()
#     os.chdir(self.FEP + '/analysis')
#     if not os.path.exists('pdbs'):
#         os.mkdir('pdbs')

#     libfiles = glob.glob('../inputfiles/*.lib')
#     re_files = glob.glob('../FEP*/*/*/*.re')
#     topology = glob.glob('../inputfiles/*.top')[0]

#     with open('../inputfiles/qprep.inp') as f:
#         protlib = f.readline()

#     with open('re2pdb.inp', 'w') as outfile:
#         outfile.write('{}'.format(protlib))

#         for libfile in libfiles:
#             outfile.write('rl {}\n'.format(libfile))

#         outfile.write('rt {}\n'.format(topology))

#         for re_file in re_files:
#             pdb_out = re_file.split('/')[-1][:-3]
#             repeat = '{:02d}'.format(int(re_file.split('/')[3]))
#             pdb_out = 'pdbs/{}_{}'.format(repeat, pdb_out)
#             outfile.write('rx {}\n'.format(re_file))
#             outfile.write('wp {}.pdb\n'.format(pdb_out))
#             outfile.write('y\n')

#         outfile.write('mask none\n')
#         outfile.write('mask not excluded\n')
#         outfile.write('wp pdbs/complexnotexcluded.pdb\n')
#         outfile.write('y\n')

#         outfile.write('q\n')

#     qprep = CLUSTER_DICT[self.cluster]['QPREP']
#     options = ' < re2pdb.inp > re2pdb.out'
#     run_command(qprep, options, string = True)

#     os.chdir(curdir)


if __name__ == "__main__":
    main_exe()
